---
title: Configuring BOSH Directors on vSphere
owner: Ops Manager
iaas: vSphere
---

<strong><%= modified_date %></strong>

This topic describes how to configure the BOSH Director for VMware vSphere.

<p class="note warning"><strong>WARNING:</strong> If you are installing Pivotal Container Service (PKS)
on vSphere with NSX-T integration, follow the instructions in
<a href="https://docs.pivotal.io/runtimes/pks/1-2/vsphere-nsxt-om-config.html">Configuring BOSH Director with NSX-T for PKS</a>
instead of performing the procedure described in this topic.</p>

* Before you begin this procedure, you must complete all steps in [Deploying Ops Manager to vSphere](./deploy.html).
* After you complete this procedure, follow the configuration instructions for the runtime you choose to install.
</br>
</br>
For example:
    <ul>
    <li> To install Pivotal Application Service (PAS), see [Deploying PAS on vSphere](https://docs.pivotal.io/pivotalcf/2-3/customizing/config-er-vmware.html).
    <li> To install PKS, see [Installing PKS on vSphere](https://docs.pivotal.io/runtimes/pks/1-3/installing-pks-vsphere.html).
    </ul>
    <p class="note"><strong>Note</strong>: We strongly recommend installing PAS and PKS on separate instances of Ops Manager for security reasons. For more information, see <a href="https://docs.pivotal.io/runtimes/pks/pas-and-pks.html">PAS and PKS Deployments with Ops Manager</a>.</p>

See [Installing Runtimes](https://docs.pivotal.io/pivotalcf/2-3/customizing/runtimes.html) for more information about Pivotal Cloud Foundry (PCF) runtimes.

<p class="note"><strong>Note:</strong> You can also perform the procedures in this topic using the Ops Manager API. For more information, see <a href="https://docs.pivotal.io/pivotalcf/2-3/customizing/ops-man-api.html">Using the Ops Manager API</a>.</p>

##<a id='prerequisites'></a>Prerequisite

Before you begin this procedure, ensure that you have successfully completed <a href="./deploy.html">Deploying Ops Manager on vSphere</a>.

## <a id="set-up"></a>Step 1: Set Up Ops Manager Authentication

1. When Ops Manager starts for the first time, you must choose one of the following:
    * [Internal Authentication](#internal): If you use Internal Authentication, PCF maintains your user database.
    * [SAML Identity Provider](#saml): If you use a SAML Identity Provider (IdP), an external identity server maintains your user database.
    * [LDAP Server](#ldap): If you use a LDAP Server, an external identity server maintains your user database.

    <%= image_tag("../common/images/select-authentication.png") %>

### <a id='internal'></a> Internal Authentication

1. Select **Internal Authentication** and provide the following information:
   * **Username**, **Password**, and **Password confirmation** to create an Admin user.
   * **Decryption passphrase** and the **Decryption passphrase confirmation**. This passphrase encrypts the Ops Manager datastore, and is not recoverable.
   * **HTTP proxy** or **HTTPS proxy**, follow the instructions in [Configuring Proxy Settings for the BOSH CPI](https://docs.pivotal.io/pivotalcf/customizing/pcf-director-proxy-settings.html).
   * Read the **End User License Agreement**, and select the checkbox to accept the terms.
   * Click **Setup Authentication**. It will take a few minutes to initialize the database.

   <%= image_tag("../common/images/vsphere/vsphere_om-deploy-09.png") %>

1. Log in to Ops Manager with the user name and password you created.

    <%= image_tag("../common/images/om-login.png") %>
    <%= image_tag("../common/images/cf-login.png") %>

1. Verify success.<br/><br/>

    You should be able to log in, and you should see the BOSH Director tile is present and ready for configuration, indicated by the orange color.

    <%= image_tag("../common/images/vsphere/vsphere_bosh-config-01.png") %>

### <a id='saml'></a> SAML Identity Provider

<%= partial '../common/using_saml_idp_ops_manager' %>

### <a id='ldap'></a> LDAP Server

<%= partial '../common/using_ldap_server_ops_manager' %>

## <a id='vcenter-config'></a>Step 2: Configure vCenter

1. Click the **BOSH Director for vSphere** tile.

    <%= image_tag("../common/images/vsphere/vsphere_bosh-config-01.png") %>

1. Select **vCenter Config**.

1. Enter the following information:
    * **vCenter Host**: The hostname of the vCenter that manages ESXi/vSphere.
    * **vCenter Username**: A vCenter username with create and delete privileges for virtual machines (VMs) and folders.
    * **vCenter Password**: The password for the vCenter user specified above.
    * **Datacenter Name**: The name of the datacenter as it appears in vCenter.
    * **Virtual Disk Type**: The Virtual Disk Type to provision for all VMs. For guidance on selecting a virtual disk type, see [vSphere Virtual Disk Types](../../customizing/disk-format.html).
    * **Ephemeral Datastore Names (comma delimited)**: The names of the datastores that store ephemeral VM disks deployed by Ops Manager.
    * **Persistent Datastore Names (comma delimited)**: The names of the datastores that store persistent VM disks deployed by Ops Manager.

    <%= image_tag("../common/images/vsphere/vsphere_bosh-config-02.png") %>

1. Select the type of networking you are using. <br/><br/>

    If you are configuring BOSH Director for PKS, select **Standard vCenter Networking**. Do not choose **NSX Networking** if you are using PKS. Choosing the container network interface (CNI), either Flanel or NSX-T, is made during the configuration of the PKS tile. <br/><br/>If you are configuring BOSH for PKS with NSX-T, see [Intalling PKS on vSphere with NSX-T Data Center](vsphere-nsxt-index.html). 

    <%= image_tag("../common/images/vsphere/vsphere_bosh-config-03.png") %>

1. Configure the following folder names:
    * If you are using PKS:
       * **VM Folder**: The vSphere datacenter folder where Ops Manager places VMs. Enter `pks_vms`.
       * **Template Folder**: The vSphere datacenter folder where Ops Manager places VMs. Enter `pks_templates`.
       * **Disk path Folder**: The vSphere datastore folder where Ops Manager creates attached disk images. You must not nest this folder. Enter `pks_disk`.
    <p class="note"><strong>Note</strong>: After initial deployment, you cannot edit folder names.</p>

1. Click **Save**.

## <a id='dir-config'></a>Step 3: Configure BOSH Director

1. Select **Director Config**.

    <%= image_tag("../common/images/vsphere/vsphere_bosh-config-06.png") %>

1. In the **NTP Servers (comma delimited)** field, enter your NTP server addresses.

    <p class="note"><strong>Note:</strong> The NTP server configuration only updates
    after VM recreation. Ensure that you select the <strong>Recreate all VMs</strong> checkbox
    if you modify the value of this field.</p>

1. Leave the **JMX Provider IP Address** field blank.
    <p class="note"><strong>Note</strong>: Starting from PCF v2.0, BOSH-reported system metrics are available in the Loggregator Firehose by default.</p>
1. Leave the **Bosh HM Forwarder IP Address** field blank.
    <p class="note"><strong>Note:</strong> Starting from PCF v2.0, BOSH-reported component metrics are available in the Loggregator Firehose by default.</p>
1. Select the **Enable VM Resurrector Plugin** to enable BOSH Resurrector functionality.
1. Select **Enable Post Deploy Scripts** to run a post-deploy script after deployment. This script allows the job to execute additional commands against a deployment.
  <p class="note"><strong>Note</strong>: You must enable post-deploy scripts to install PKS.</p>

1. Select **Recreate all VMs** to force BOSH to recreate all VMs on the next deploy. This process does not destroy any persistent disk data.

1. Select **Enable bosh deploy retries** if you want Ops Manager to retry failed BOSH operations up to five times.
1. Select **Keep Unreachable Director VMs** if you want to preserve BOSH Director VMs after a failed deployment for troubleshooting purposes.
1. Select **HM Pager Duty Plugin** to enable Health Monitor integration with PagerDuty.

    <%= image_tag("../common/images/director_hm_pager.png") %>
    * **Service Key**: Enter your API service key from PagerDuty.
    * **HTTP Proxy**: Enter an HTTP proxy for use with PagerDuty.
1. Select **HM Email Plugin** to enable Health Monitor integration with email.

    <%= image_tag("../common/images/director_hm_email.png") %>
    * **Host**: Enter your email hostname.
    * **Port**: Enter your email port number.
    * **Domain**: Enter your domain.
    * **From**: Enter the address for the sender.
    * **Recipients**: Enter comma-separated addresses of intended recipients.
    * **Username**: Enter the username for your email server.
    * **Password**: Enter the password for your email server.
    * **Enable TLS**: Select this checkbox to enable Transport Layer Security.
1. Select a **Blobstore Location** to either configure the blobstore as an internal server or an external endpoint. Because the internal server is unscalable and less secure, Pivotal recommends you configure an external blobstore.
  <p class="note"><strong>Note</strong>: After you deploy Ops Manager, you cannot change the blobstore location.</p>
  * **Internal**: Select this option to use an internal blobstore. Ops Manager creates a new VM for blob storage. No additional configuration is required.
  * **S3 Compatible Blobstore**: Select this option to use an external S3-compatible endpoint. Follow the procedures in [Sign up for Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/gsg/SigningUpforS3.html) and [Create a Bucket](https://docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html) in the AWS documentation. When you have created an S3 bucket, complete the following steps:
      1. **S3 Endpoint**: Navigate to the [Regions and Endpoints](http://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region) topic in the AWS documentation. Locate the endpoint for your region in the **Amazon Simple Storage Service (S3)** table and construct a URL using your region's endpoint. For example, if you are using the `us-west-2` region, the URL you create would be https://s3-us-west-2.amazonaws.com. Enter this URL into the **S3 Endpoint** field in Ops Manager.
      1. **Bucket Name**: Enter the name of the S3 bucket.
      1. **Access Key** and **Secret Key**: Enter the keys you generated when creating your S3 bucket.
      1. Select **V2 Signature** or **V4 Signature**. If you select **V4 Signature**, enter your **Region**.
        <p class="note"><strong>Note</strong>: AWS recommends using Signature Version 4. For more information about AWS S3 Signatures, see <a href="http://docs.aws.amazon.com/AmazonS3/latest/API/sig-v4-authenticating-requests.html">Authenticating Requests</a> in the AWS documentation.</p>
  * **GCS Blobstore**: Select this option to use an external Google Cloud Storage (GCS) endpoint. To create a GCS bucket, you will need a GCS account. Follow the procedures in [Creating Storage Buckets](https://cloud.google.com/storage/docs/creating-buckets) in the GCP documentation. Once you have created a GCS bucket, complete the following steps:
        1. **Bucket Name**: Enter the name of your GCS bucket.
        1. **Storage Class**: Select the storage class for your GCS bucket. For more information, see [Storage Classes](https://cloud.google.com/storage/docs/storage-classes) in the GCP documentation.
        1. **Service Account Key**: Follow the steps in the [Set up an IAM Service Account](https://docs.pivotal.io/pcf/om/2-2/gcp/prepare-env-manual.html#iam_account) section of _Preparing to Deploy PCF on GCP_ to download a JSON file with a private key, and then enter the contents of the JSON file into the field.

        <%= image_tag("../common/images/gcp/blobstore.png") %>

1. By default, PCF deploys and manages an **Internal** database for you. If you choose to use an **External MySQL Database**, complete the associated fields with information obtained from your external MySQL Database provider: **Host**, **Port**, **Username**, **Password**, and **Database**.

    <%= image_tag("../common/images/director_database.png") %>

1. (Optional) **Director Workers** sets the number of workers available to execute Director tasks. This field defaults to `5`.
1. (Optional) **Max Threads** sets the maximum number of threads that the BOSH Director can run simultaneously. For vSphere, the default value is `32`. Leave the field blank to use this default value. Pivotal recommends that you use the default value unless doing so results in rate limiting or errors on your IaaS.
1. (Optional) To add a custom URL for your BOSH Director, enter a valid hostname in **Director Hostname**. You can also use this field to configure a load balancer in front of your BOSH Director. For more information, see [How to Set Up a Load Balancer in Front of Operations Manager Director](https://community.pivotal.io/s/article/How-to-Set-Up-a-Load-Balancer-in-Front-of-Ops-Manager-Director) in Pivotal Support.<br/>
    <p class="note warning"><strong>WARNING</strong>:
    In Ops Manager v2.3.2 and earlier, if you change the <b>Director Hostname</b> after your initial deployment, VMs become unavailable. This causes PCF downtime. To restore VM availability, enable <b>Recreate All VMs</b> and redeploy. This issue is resolved in Ops Manager v2.3.3 and later.
    </p>
1. (Optional) To set a custom banner that users see when logging in to the Director using SSH, enter text in the **Custom SSH Banner** field.
  <%= image_tag("../common/images/director_workers.png") %>
1. Click **Save**.

## <a id='create-az'></a>Step 4: Create Availability Zones
Ops Manager Availability Zones (AZs) correspond to your vCenter clusters and resource pools. Multiple AZs allow you to provide high availability and load balancing to your applications. When you run more than one instance of an application, Ops Manager balances those instances across all of the AZs assigned to the application. At least three AZs are recommended for a highly available installation of your chosen runtime.
  <p class="note"><strong>Note</strong>: For more information about using AZs in vSphere, see <a href="https://docs.pivotal.io/pivotalcf/customizing/understand-az.html">Understanding Availability Zones in VMware Installations</a> in the PCF documentation.</p>

1. Select **Create Availability Zones**.

    <%= image_tag("../common/images/vsphere/vsphere_bosh-config-07.png") %>

1. Use the following steps to create one or more AZs for PKS to use:
    * Click **Add** and create the PKS Management AZ.
    * Enter a unique **Name** for the AZ, such as `AZ-MGMT`.
    * Select the IaaS configuration, `vSphere` or `vCenter`.
    * Enter the name of an existing vCenter **Cluster** to use as an AZ, such as `COMP-Cluster-1`.
    * Enter the name of the PKS Management **Resource Pool** in the vCenter cluster that you specified above, such as `RP-MGMT-PKS`. The jobs running in this AZ share the CPU and memory resources defined by the pool.
    * Click **Add Cluster** and create at least one PKS Compute AZ.
    * Specify the **Cluster** and the **Resource Pool**, such as `RP-PKS-AZ`.
    * Add additional clusters as necessary. Click the trash icon to delete a cluster. The first cluster cannot be deleted.

    <%= image_tag("../common/images/vsphere/vsphere_bosh-config-08.png") %>

    <%= image_tag("../common/images/vsphere/vsphere_bosh-config-09.png") %>

1. Click **Save**.

    <%= image_tag("../common/images/vsphere/vsphere_bosh-config-10.png") %>

## <a id='create-networks'></a>Step 5: Create Networks Page

1. Select **Create Networks**.
  <p class='note'><strong>Note</strong>: If you use the Cisco Nexus
1000v Switch, see <a href="https://docs.pivotal.io/pivotalcf/customizing/nexus-switch.html">Using the Cisco Nexus 1000v Switch with Ops Manager</a> in the PCF documentation for more information.</p>

1. Select **Enable ICMP checks** to enable ICMP on your networks. The BOSH Director uses ICMP checks to confirm that components within your network are reachable.

1. Click **Add Network** and create the following networks:
  * `pks-infrastructure`: This network is for Ops Manager, the BOSH Director, the PKS broker, and the PKS API.
  * `pks-main`: If you have a large deployment with multiple tiles, you can choose to deploy the PKS broker and PKS API to a separate network named `pks-main`. See the table below for more information.
  * `pks-services`: Network for creating the master and worker VMs for Kubernetes clusters. The CIDR should not conflict with the pod overlay network `10.200.0.0/16` or the reserved Kubernetes services CIDR of `10.100.200.0/24`.
  <p class="note"><strong>Note</strong>: Multiple networks allow you to place vCenter on a private network and the rest of your deployment on a public network. Isolating vCenter in this manner denies access to it from outside sources and reduces possible security vulnerabilities.</p>
  Use the values from the following table as a guide when you create each network, replacing the IP addresses with ranges that are available in your vSphere environment:
  <table>
    <tr>
      <th rowspan="7">Infrastructure<br> Network</th>
      <th>Field</th>
      <th>Configuration</th>
    </tr>
    <tr>
      <td>Name</td>
      <td><code>pks-infrastructure</code></td>
    </tr>
    <tr>
      <td>vSphere Network Name</td>
      <td><code>MY-PKS-virt-net/MY-PKS-subnet-infrastructure</code></td>
    </tr>
    <tr>
      <td>CIDR</td>
      <td><code>192.168.101.0/26</code></td>
    </tr>
    <tr>
      <td>Reserved IP Ranges</td>
      <td><code>192.168.101.1-192.168.101.9</code></td>
    </tr>
    <tr>
      <td>DNS</td>
      <td><code>192.168.101.2</code></td>
    </tr>
    <tr>
      <td>Gateway</td>
      <td><code>192.168.101.1</code></td>
    </tr>
      <tr>
      <th rowspan="7">Main Network (Optional)</th>
      <th>Field</th>
      <th>Configuration</th>
    </tr>
    <tr>
      <td>Name</td>
      <td><code>pks-main</code></td>
    </tr>
    <tr>
      <td>vSphere Network Name</td>
      <td><code>MY-PKS-virt-net/MY-PKS-subnet-pks</code></td>
    </tr>
    <tr>
      <td>CIDR</td>
      <td><code>192.168.16.0/26</code></td>
    </tr>
    <tr>
      <td>Reserved IP Ranges</td>
      <td><code>192.168.16.1-192.168.16.9</code></td>
    </tr>
    <tr>
      <td>DNS</td>
      <td><code>192.168.16.2</code></td>
    </tr>
    <tr>
      <td>Gateway</td>
      <td><code>192.168.16.1</code></td>
    </tr>
    <tr>
      <th rowspan="7">Service Network</th>
      <th>Field</th>
      <th>Configuration</th>
    </tr>
    <tr>
      <td>Name</td>
      <td><code>pks-services</code></td>
    </tr>
    <tr>
      <td>vSphere Network Name</td>
      <td><code>MY-PKS-virt-net/MY-PKS-subnet-services</code></td>
    </tr>
    <tr>
      <td>CIDR</td>
      <td><code>192.168.20.0/22</code></td>
    </tr>
    <tr>
      <td>Reserved IP Ranges</td>
      <td><code>192.168.20.1-192.168.20.9</code></td>
    </tr>
    <tr>
      <td>DNS</td>
      <td><code>192.168.20.2</code></td>
    </tr>
    <tr>
      <td>Gateway</td>
      <td><code>192.168.20.1</code></td>
    </tr>
  </table>

1. Select which **Availability Zones** to use with the network.
1. Click **Save**.

## <a id='assign-azs'></a>Step 6: Assign AZs and Networks

1. Select **Assign AZs and Networks**.

1. Use the drop-down menu to select a **Singleton Availability Zone**. The BOSH Director installs in this AZ. For PKS, this is the `AZ-MGMT` AZ.

1. Use the drop-down menu to select a **Network** for the BOSH Director. The BOSH Director runs in the PKS Management Plane network. Select the `NST-MGMT-PKS` network.

1. Click **Save**.

## <a id='security-config'></a> Step 7: Security Page

In **Trusted Certificates**, enter a custom certificate authority (CA) certificate to insert into your organization's certificate trust chain. This allows all BOSH-deployed components in your deployment to trust a custom root certificate. If you are using a private [Docker registry](https://docs.pivotal.io/pivotalcf/opsguide/docker-registry.html), such as VMware Harbor, use this field to enter the certificate for the registry. See [Integrating Harbor Registry with PKS](https://docs.pivotal.io/partners/vmware-harbor/integrating-pks.html) for details.

<%= partial "../common/security-pane" %>

## <a id='syslog'></a> Step 8: Syslog Page

<p class="note"><strong>Note:</strong> BOSH Director logs contain sensitive information that should be considered privileged. For example, these logs may contain cloud provider credentials. If you choose to forward logs to an external syslog endpoint, use TLS encryption to prevent information from being intercepted by a third party.</p>

<%= partial '../common/syslog_bosh' %>

## <a id='resource-config'></a> Step 9: Resource Config Page

1. Select **Resource Config**.

    <%= image_tag("../common/images/vsphere-om-resources.png") %>

1. Adjust any values as necessary for your deployment. Under the **Instances**, **Persistent Disk Type**, and **VM Type** fields, choose **Automatic** from the dropdown to allocate the recommended resources for the job. If the **Persistent Disk Type** field reads **None**, the job does not require persistent disk space.
    <p class="note"><strong>Note:</strong> Ops Manager requires a Director VM with at least 8&nbsp;GB memory.</p>
    <p class="note"><strong>Note:</strong> If you set a field to <strong>Automatic</strong> and the recommended resource allocation changes in a future version, Ops Manager automatically uses the updated recommended allocation.</p>
    <p class="note"><strong>Note:</strong> If you install PAS for Windows, provision your <strong>Master Compilation Job</strong>
    with at least 100&nbsp;GB of disk space.</p>

1. Click **Save**.

## <a id="custom-vm-extensions"></a> Step 10: (Optional) Add Custom VM Extensions

<%= partial "../common/vm-extension-config"  %>

## <a id='complete-installation'></a> Step 11: Complete the BOSH Director Installation

1. Click the **Installation Dashboard** link to return to the Installation Dashboard.

1. Click **Review Pending Changes**. Select the product that you intend to deploy and review the changes. For more information, see [Reviewing Pending Product Changes](https://docs.pivotal.io/pivotalcf/2-3/customizing/review-pending-changes.html).

1. After you complete this procedure, follow the instructions in [Deploying PAS on vSphere](https://docs.pivotal.io/pivotalcf/2-3/customizing/config-er-vmware.html). If you are installing PKS, proceed to [Installing PKS on vSphere](https://docs.pivotal.io/runtimes/pks/1-2/installing-pks-vsphere.html).

##<a id='next'></a> Next Steps

To install PKS on vSphere <strong>without</strong> NSX-T integration, perform the procedures in [Installing PKS on vSphere](installing-pks-vsphere.html).

To use Harbor to store and manage container images, see [Installing and Integrating VMware Harbor Registry](https://docs.pivotal.io/partners/vmware-harbor/).